# CausalKnowledgeTrace: Interactive DAG Visualization and Causal Knowledge Graph Generation

CausalKnowledgeTrace is a comprehensive system for interactive visualization of Directed Acyclic Graphs (DAGs) and automated causal knowledge graph generation from biomedical literature. The system integrates a Shiny web application for visualization and configuration with a Python-based graph creation engine that queries SemMedDB for causal relationships.

## üìã What This Project Does

- **üåê Interactive Visualization**: Web-based DAG exploration with zoom, pan, and node interaction
- **üîç Graphical Causal Modeling**: Automated assembly of causal relationships from biomedical literature given Concept Unique Identifiers in the Unified Medical Language System, or [UMLS](https://www.nlm.nih.gov/research/umls/index.html), for the Exposure and Outcome of interest
- **üìä Evidence Analysis**: PMID-based evidence tracking and strength assessment
- **‚ö° Performance Optimized**: Binary formats, caching, and vectorized operations for large graphs
- **üéØ Configurable Analysis**: Enter multiple CUIs for the exposure and/or outcome; Examine 1st, 2nd, or 3rd degree relationships
- **üìÅ Multiple Formats**: R DAG files, JSON assertions, optimized binary formats

## Key Features

### üåê Shiny Web Application
- **Interactive Network Visualization**: Explore DAGs with zoom, pan, and node selection capabilities
- **Dynamic Node Information**: Click on nodes to see detailed information and evidence
- **Physics Controls**: Adjust network layout parameters in real-time
- **Statistics Dashboard**: View network statistics and node distributions
- **Color-coded Categories**: Three-category system (Exposure/Outcome/Other) with optimized performance
- **Flexible Data Loading**: Load DAG structures from generated files or upload custom R files
- **Graph Configuration Interface**: Configure parameters for knowledge graph generation
- **Efficient Loading**: Fast loading for large graphs

### üêç Graph Creation Engine
- **Automated Knowledge Graph Generation**: Create causal graphs from SemMedDB biomedical literature
- **Multiple CUI Support**: Handle multiple Concept Unique Identifiers for exposures and outcomes
- **K-hop Analysis**: Configurable relationship depth (1-3 hops) for comprehensive graph traversal
- **Markov Blanket Analysis**: Advanced causal inference with Markov blanket computation
- **Blacklist Filtering**: Filter out generic or unwanted concepts during graph creation
- **Multiple Output Formats**: Generate R DAG objects, JSON assertion files, and optimized binary formats
- **Performance Monitoring**: Detailed timing analysis and execution metrics

## Project Structure

The project is organized into two main components with clear separation of concerns:

```
CausalKnowledgeTrace/
‚îú‚îÄ‚îÄ README.md                    # This documentation file
‚îú‚îÄ‚îÄ setup.sh                    # Automated setup script using conda environment
‚îú‚îÄ‚îÄ run_app.R                    # Enhanced launch script for Shiny application
‚îú‚îÄ‚îÄ user_input.yaml              # Configuration file (generated by Shiny app)
‚îú‚îÄ‚îÄ packages.R                   # R package installation script
‚îú‚îÄ‚îÄ .env                         # Database credentials (create from doc/smaple.env)
‚îÇ
‚îú‚îÄ‚îÄ doc/                         # Setup and configuration files
‚îÇ   ‚îú‚îÄ‚îÄ environment.yaml         # Conda environment specification
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ packages.R               # R package installation script
‚îÇ   ‚îú‚îÄ‚îÄ smaple.env               # Sample environment variables template
‚îÇ   ‚îî‚îÄ‚îÄ filter.sql               # Database filtering queries for generic CUIs
‚îÇ
‚îú‚îÄ‚îÄ shiny_app/                   # Shiny Web Application Component
‚îÇ   ‚îú‚îÄ‚îÄ app.R                    # Main Shiny application file
‚îÇ   ‚îú‚îÄ‚îÄ dag_data.R               # DAG data configuration file
‚îÇ   ‚îú‚îÄ‚îÄ modules/                 # Modular Shiny components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dag_visualization.R  # Network visualization module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ node_information.R   # Node information display module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ statistics.R         # Statistics and analytics module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_upload.R        # Data loading and file management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ causal_analysis.R    # Causal analysis functionality
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graph_cache.R        # Graph caching system
‚îÇ   ‚îú‚îÄ‚îÄ server/                  # Server-side logic modules
‚îÇ   ‚îú‚îÄ‚îÄ ui/                      # UI component modules
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Utility functions
‚îÇ
‚îî‚îÄ‚îÄ graph_creation/              # Graph Creation Engine Component
    ‚îú‚îÄ‚îÄ pushkin.py               # Main entry point (delegates to cli_interface.py)
    ‚îú‚îÄ‚îÄ cli_interface.py         # Command line interface and argument parsing
    ‚îú‚îÄ‚îÄ analysis_core.py         # Core analysis classes (GraphAnalyzer, MarkovBlanketAnalyzer)
    ‚îú‚îÄ‚îÄ config_models.py         # Configuration models and validation
    ‚îú‚îÄ‚îÄ database_operations.py   # Database connection and query operations
    ‚îú‚îÄ‚îÄ graph_operations.py      # Graph construction and manipulation
    ‚îú‚îÄ‚îÄ markov_blanket.py        # Markov blanket computation algorithms
    ‚îú‚îÄ‚îÄ post_process_optimization.py # File optimization (disabled)
    ‚îú‚îÄ‚îÄ config.py                # Backward compatibility wrapper
    ‚îú‚îÄ‚îÄ consolidation.py         # Graph consolidation utilities
    ‚îú‚îÄ‚îÄ SemDAGconsolidator.py    # SemMedDB DAG consolidation
    ‚îú‚îÄ‚îÄ example/                 # Example scripts and configurations
    ‚îÇ   ‚îú‚îÄ‚îÄ run_pushkin.sh       # Complete pipeline execution script
    ‚îÇ   ‚îî‚îÄ‚îÄ run_consolidation.sh # Consolidation-only script
    ‚îú‚îÄ‚îÄ result/                  # Generated output files
    ‚îÇ   ‚îú‚îÄ‚îÄ MarkovBlanket_Union.R
    ‚îÇ   ‚îú‚îÄ‚îÄ degree_X.R           # X = K-hops value (1, 2, or 3)
    ‚îÇ   ‚îú‚îÄ‚îÄ causal_assertions_X.json
    ‚îÇ   ‚îî‚îÄ‚îÄ performance_metrics.json
    ‚îî‚îÄ‚îÄ output/                  # Alternative output directory
```

## Prerequisites

### System Requirements
- **PostgreSQL** database with modified SemMEDdb data (for graph creation) in postgres
- **Conda/Miniconda**: For environment management (recommended)
- **Python** (version 3.11 or higher)
- **R** (version 4.0 or higher): Download from [https://cran.r-project.org/](https://cran.r-project.org/)

### Database Requirements
- PostgreSQL database with SemMedDB schema
- Database connection parameters (host, port, username, password, database name)
- Properly configured `causalehr` schema with causalpredication table

## Installation

# PostgreSQL Database Setup for SemMedDB

This document provides step-by-step instructions for setting up a modified version of SemMedDB in PostgreSQL format.

## Database Download

We created a modified version of [SemMedDB](https://skr3.nlm.nih.gov/SemMedDB/) that is available in PostgreSQL format.

**Download Link**: https://drive.google.com/file/d/1842FzR1viGkKU3IdqMpBlD2GnupuGF1n/view?usp=drive_link

**Note**: The database file is approximately 25GB in size, so download may take several minutes depending on your internet connection.

## Prerequisites

* PostgreSQL must be installed on your system
* Sufficient disk space (at least 50GB recommended for extraction and setup)

## Database Setup Instructions

### Step 1: Create the Database

Replace `<username>` with your actual PostgreSQL username.
```bash
createdb -U <username> -h localhost causalehr
```

### Automated Setup 

The project includes an automated setup script that creates a conda environment and installs all dependencies:

```bash
# Clone or download the project
cd CausalKnowledgeTrace

# 1. Create environment configuration file
cp doc/smaple.env .env
# Edit .env with your database credentials (see Database Configuration below)

# 2. Run the automated setup script
chmod +x setup.sh
./setup.sh
```

This script will:
1. Create a conda environment named `causalknowledgetrace` using `doc/environment.yaml`
2. Install Python dependencies (psycopg2, PyYAML, pandas, networkx, scipy, numpy, matplotlib, jupyter, rpy2)
3. Install R packages using `doc/packages.R`

### Database Configuration

Before running graph creation, you need to configure your database connection:

```bash
# Copy the sample environment file
cp doc/smaple.env .env

# Edit the .env file with your database credentials
nano .env  # or use your preferred editor
```

The `.env` file should contain:
```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_USER=your_username
DB_PASSWORD=your_password
DB_NAME=your_database_name
DB_SCHEMA=causalehr
```

**Important**:
- Replace the placeholder values with your actual database credentials
- The `.env` file is ignored by git for security (contains sensitive information)
- Make sure your database contains the SemMedDB schema with causalpredication table

### Manual Installation

If you prefer manual installation or the automated setup fails:

#### 1. Setup Environment Configuration

```bash
# Copy the sample environment file
cp doc/smaple.env .env

# Edit with your database credentials
nano .env  # or use your preferred editor
```

#### 2. Create Conda Environment

```bash
# Create environment from YAML file
conda env create -f doc/environment.yaml

# Activate the environment
conda activate causalknowledgetrace
```

#### 3. Install Python Dependencies

```bash
# Using pip with requirements file
pip install -r doc/requirements.txt

# Or install individually
pip install psycopg2-binary PyYAML pandas networkx scipy rpy2
```

#### 4. Install R Packages

```r
# Run the R package installation script
source("doc/packages.R")

# Or install core packages manually
install.packages(c(
    "shiny", "shinydashboard", "visNetwork", "dplyr", "DT",
    "dagitty", "igraph", "yaml", "shinyjs", "SEMgraph",
    "ggplot2", "testthat", "knitr", "rmarkdown"
))
```

## Quick Start

### 1. Environment Setup

```bash
# Activate the conda environment (if using conda setup)
conda activate causalknowledgetrace

# Or ensure you're in the project directory
cd /path/to/CausalKnowledgeTrace
```

### 2. Running the Shiny Application

```bash
# Launch the enhanced Shiny application
Rscript run_app.R


```

**Features of the enhanced launcher:**
- Automatic port detection and conflict resolution
- Graph cache initialization
- Detailed startup information and troubleshooting

**Access the application:**
- The app will automatically open in your browser
- Look for the complete URL in the console output (e.g., `http://127.0.0.1:3838`)
- If port 3838 is in use, the launcher will automatically find an available port

### 3. Running the Graph Creation Engine

The graph creation engine can be used in multiple ways depending on your workflow:

#### Method 1: Through Shiny Web App (Recommended)
1. **Launch Shiny app**: `Rscript run_app.R`
2. **Configure parameters** using the "Graph Configuration" tab
3. **Generate graphs** directly through the web interface
4. **Visualize results** automatically in the same application

#### Method 2: Manual Testing (Optional - for development/testing)
This method allows you to test the graph creation engine independently without the web app:

1. **Configure parameters** using the Shiny app's "Graph Configuration" tab OR manually edit `user_input.yaml`
2. **Run graph creation manually**:
   ```bash
   cd graph_creation
   python pushkin.py --yaml-config ../user_input.yaml --host localhost --port 5432 --dbname causalehr --user your_username --password your_password --schema causalehr
   ```
3. **Load results** in Shiny app using "Data Upload" tab

#### Method 3: Using Example Script (Uses .env file)
```bash
# Ensure .env file is configured with database credentials
cp doc/smaple.env .env
nano .env  # Edit with your credentials

# Run the complete pipeline
./graph_creation/example/run_pushkin.sh
```

#### Method 4: Direct Command Line with Predefined Configs
```bash
cd graph_creation
python pushkin.py --config hypertension_alzheimers --host localhost --port 5432 --dbname causalehr --user your_username --password your_password --schema causalehr --markov-blanket
```

**When to use each method:**
- **Method 1**: Best for regular use, integrated workflow
- **Method 2**: Useful for testing, debugging, or batch processing
- **Method 3**: Convenient for automated pipelines
- **Method 4**: Quick testing with predefined configurations

## Configuration and Workflow

### Typical User Workflow (Recommended)

For most users, the integrated web application provides the complete workflow:

1. **Launch Application**: `Rscript run_app.R`
2. **Configure Analysis**: Use "Graph Configuration" tab to set parameters
3. **Generate Graphs**: Click "Create Graph" to generate directly in the app
4. **Visualize Results**: Automatically load and explore generated graphs
5. **Interactive Analysis**: Use all visualization and analysis features

### Developer/Testing Workflow (Optional)

For development, testing, or batch processing, you can use the command-line interface:

1. **Configure Parameters**: Edit `user_input.yaml` or use Shiny app
2. **Test Graph Creation**: Run Python engine manually to test configurations
3. **Verify Results**: Check generated files before loading in web app
4. **Load in App**: Use "Data Upload" tab to load manually generated graphs

### Complete Workflow Details

1. **Configure Parameters**: Use the Shiny app's "Graph Configuration" tab to set:
   - **Exposure CUIs**: Multiple Concept Unique Identifiers for exposure variables
   - **Outcome CUIs**: Multiple Concept Unique Identifiers for outcome variables
   - **Blacklist CUIs**: CUIs to exclude from analysis (optional)
   - **Minimum PMIDs**: Threshold for minimum unique publications (evidence strength)
   - **Publication Year Cutoff**: Exclude publications before this year
   - **K-hops Parameter**: Relationship depth (1-3 hops)
   - **Predication Types**: Types of causal relationships to include
   - **SemMedDB Version**: Database version to use

2. **Save Configuration**: Click "Create Graph" to save parameters to `user_input.yaml`

3. **Generate Graph**: Run the graph creation engine with database credentials

4. **Automatic Integration**: Generated graphs are saved to `graph_creation/result/` directory:
   - JSON files (`causal_assertions_X.json`)
   - R DAG files (`degree_X.R`, `MarkovBlanket_Union.R`)

5. **Visualize Results**: Use the Shiny app's "Data Upload" tab to load and visualize generated graphs

### YAML Configuration Format

The `user_input.yaml` file supports the following structure:

```yaml
# Multiple CUIs supported for both exposure and outcome
exposure_cuis:
  - C0020538  # Hypertension
  - C4013784  # Hypertensive disease
  - C0221155  # High blood pressure
outcome_cuis:
  - C2677888  # Alzheimer's disease
  - C0750901  # Dementia
  - C0494463  # Cognitive impairment

# Optional blacklist to exclude generic concepts
blacklist_cuis:
  - C0001687  # Generic concept to exclude
  - C0002526  # Another generic concept

# Custom names (optional)
exposure_name: "Hypertension"
outcome_name: "Alzheimers"

# Analysis parameters
min_pmids: 10                    # Minimum publications required
pub_year_cutoff: 2010           # Exclude publications before 2010
k_hops: 1                       # Relationship depth (1-3)
predication_type: "CAUSES"      # Single type or list
SemMedDBD_version: "heuristic"  # Database version
```

### Predication Types

The system supports multiple predication types:
- **Single type**: `predication_type: "CAUSES"`
- **Multiple types**: `predication_type: ["CAUSES", "TREATS", "PREVENTS"]`

Common types: `CAUSES`, `TREATS`, `PREVENTS`, `INTERACTS_WITH`, `AFFECTS`, `ASSOCIATED_WITH`, `PREDISPOSES`, `COMPLICATES`

## Data Loading and Visualization

### Loading Generated Graphs (Recommended Workflow)

The application provides optimized loading for graphs generated by the Python engine:

#### Method 1: Generated Graph Files
1. **Generate graphs** using the graph creation engine
2. **Files are saved** to `graph_creation/result/` directory:
   - `degree_X.R` - Standard DAG files (X = k-hops value)
   - `MarkovBlanket_Union.R` - Markov blanket analysis results
   - `causal_assertions_X.json` - Evidence data

3. **Load in Shiny app**:
   - Go to "Data Upload" tab
   - Click "Refresh File List" to scan for available files
   - Select your generated file from the dropdown
   - Click "Load Selected DAG"

#### Method 2: Upload Custom DAG Files
1. **Go to "Data Upload" tab** in the Shiny app
2. **Use file upload interface** to select your R file
3. **Click "Upload & Load"** to upload and immediately load the DAG

### DAG File Format

DAG files should contain a dagitty graph definition with variable name `g`:

```r
# Example DAG file format
g <- dagitty('dag {
    Hypertension [exposure]
    Alzheimers_Disease [outcome]
    Age
    BMI
    Diabetes

    Age -> Hypertension
    BMI -> Diabetes
    Hypertension -> Alzheimers_Disease
    Diabetes -> Alzheimers_Disease
    Age -> Alzheimers_Disease
}')
```

### Performance Features

The application includes several performance features:
- **Automatic file detection** and validation
- **Graph caching system** for repeated access
- **Node categorization** using vectorized operations
- **Progressive loading** with status indicators

### Node Categories and Visualization

The application uses an optimized three-category system for node classification:

- **üî¥ Exposure** (Red #FF4500): Variables marked as `[exposure]` in the DAG
- **üîµ Outcome** (Blue #0066CC): Variables marked as `[outcome]` in the DAG
- **‚ö´ Other** (Gray #808080): All other variables in the DAG

**Performance features:**
- Vectorized operations for categorization of large graphs
- Color assignment using batch processing
- Font sizing and edge styling for better visibility
- Progress indicators during processing

### Large Graph Support

The application is optimized for large graphs with thousands of nodes:

1. **Automatic performance scaling**:
   - Smaller font sizes for dense graphs
   - Thinner edge lines to reduce visual clutter
   - Efficient memory management
   - Progressive rendering with status updates

2. **Interactive features maintained**:
   - Zoom and pan functionality
   - Node selection and information display
   - Physics controls for layout adjustment
   - Real-time statistics updates

## Advanced Usage

### Graph Creation Options

#### Standard Graph Analysis
```bash
cd graph_creation
python pushkin.py --yaml-config ../user_input.yaml --host localhost --port 5432 --dbname causalehr --user username --password password --schema causalehr
```

#### Markov Blanket Analysis
```bash
cd graph_creation
python pushkin.py --yaml-config ../user_input.yaml --host localhost --port 5432 --dbname causalehr --user username --password password --schema causalehr --markov-blanket
```

#### Using Predefined Configurations
```bash
cd graph_creation
python pushkin.py --config hypertension_alzheimers --host localhost --port 5432 --dbname causalehr --user username --password password --schema causalehr
```



### Database Filtering

The project includes SQL filters to exclude generic concepts:
- **Generic CUI filtering**: Removes overly broad medical concepts
- **Semantic type filtering**: Excludes non-specific semantic types
- **Custom blacklists**: User-defined CUI exclusions

Filter file: `doc/filter.sql` contains predefined exclusion lists.

## Shiny Application Usage

### Application Tabs

#### 1. üìä DAG Visualization Tab (Default)
- **Interactive network diagram** with full DAG structure
- **Node interaction**: Drag to reposition, click to select and view details
- **Zoom and pan**: Mouse wheel zoom, drag to pan
- **Physics controls**: Real-time adjustment of layout parameters
- **Node removal**: Interactive removal of nodes and edges with graph updates
- **Reload DAG Data**: Refresh from current data files
- **Create Graph**: Navigate to graph configuration

#### 2. üìã Node Information Tab
- **Selected node details**: Comprehensive information about clicked nodes
- **Searchable node table**: All nodes with metadata and properties
- **Evidence information**: PMID lists and evidence counts (for generated graphs)
- **Instrumental variables**: Displayed as comma-separated lists

#### 3. üìà Statistics Tab
- **Network metrics**: Node count, edge count, group distributions
- **Visual charts**: Node distribution and category breakdowns
- **DAG structure**: Connectivity and topology information
- **Performance metrics**: Loading times and processing status

#### 4. üìÅ Data Upload Tab (Second Tab)
- **File management**: Upload and load custom DAG files
- **Generated file loading**: Access graphs created by Python engine
- **File format validation**: Automatic dagitty syntax checking
- **Status indicators**: Real-time feedback on loading progress

#### 5. ‚öôÔ∏è Graph Configuration Tab (First Tab)
- **Parameter configuration**: Set exposure/outcome CUIs, thresholds, filters
- **Multiple CUI support**: Handle complex exposure-outcome relationships
- **Blacklist management**: Exclude unwanted concepts
- **Real-time validation**: Input validation with immediate feedback
- **YAML export**: Save configuration for Python engine

### Interactive Controls

#### Physics and Layout
- **Physics Strength**: Gravitational force between nodes (-500 to -50)
- **Spring Length**: Preferred distance between connected nodes (100-400)
- **Stabilization**: Automatic layout stabilization
- **Reset Physics**: Return to default layout settings

#### Node and Edge Management
- **Node selection**: Click nodes to view detailed information
- **Node removal**: Remove nodes with automatic graph updates
- **Edge information**: Detailed evidence panels with PMID lists
- **Category filtering**: Filter by Exposure/Outcome/Other categories

## Technical Details

### Graph Creation Engine Architecture

#### Core Components
- **`pushkin.py`**: Main entry point that delegates to CLI interface
- **`cli_interface.py`**: Command-line argument parsing and validation
- **`analysis_core.py`**: Core analyzer classes:
  - `GraphAnalyzer`: General graph analysis and DAG generation
  - `MarkovBlanketAnalyzer`: Specialized Markov blanket computation
- **`config_models.py`**: Configuration validation and data models
- **`database_operations.py`**: PostgreSQL database operations and k-hop queries
- **`markov_blanket.py`**: Markov blanket algorithms for causal inference

#### Analysis Modes
1. **Standard Graph Analysis**: Basic causal graph construction from SemMedDB
2. **Markov Blanket Analysis**: Advanced causal inference with confounder identification
3. **K-hop Analysis**: Configurable relationship depth (1-3 hops) for comprehensive traversal

#### Output Formats
- **R DAG files**: `degree_X.R`, `MarkovBlanket_Union.R` (dagitty format)
- **JSON assertions**: `causal_assertions_X.json` (detailed evidence)

- **Metadata**: Performance metrics, configuration logs, timing analysis

### Shiny Application Architecture

#### Modular Design
- **`modules/dag_visualization.R`**: Network visualization with visNetwork
- **`modules/node_information.R`**: Node details and evidence display
- **`modules/statistics.R`**: Network analytics and metrics
- **`modules/data_upload.R`**: File management and loading
- **`modules/causal_analysis.R`**: Causal analysis functionality
- **`modules/graph_cache.R`**: Persistent caching system

#### Performance Features
- **Vectorized node categorization**: O(1) complexity for large graphs
- **Progressive loading**: Status indicators and chunked processing
- **Graph caching**: Persistent cache for repeated access

## Troubleshooting

### Setup Issues

#### Environment Setup
```bash
# If conda environment creation fails
conda clean --all
conda env create -f doc/environment.yaml --force

# If R package installation fails
Rscript -e "install.packages('devtools'); devtools::install_deps()"
```

#### Database Connection
```bash
# Test PostgreSQL connection
psql -h localhost -p 5432 -U username -d causalehr -c "SELECT COUNT(*) FROM causalehr.causalpredication;"

# Check schema exists
psql -h localhost -p 5432 -U username -d causalehr -c "\dt causalehr.*"
```

### Application Issues

#### Shiny Application
1. **Port conflicts**: The launcher automatically finds available ports
2. **Package loading errors**: Check console output for missing dependencies
3. **File loading failures**: Verify DAG file format and dagitty syntax
4. **Performance issues**: Check system resources and reduce k-hops if needed

#### Graph Creation Engine
1. **Database connection errors**: Verify credentials and network connectivity
2. **Environment variable issues**: Check that `.env` file is properly formatted and loaded
3. **Memory issues**: Reduce k-hops parameter or increase system memory
4. **No results returned**: Check CUI validity and database content
5. **Timeout errors**: Increase query timeout or optimize database indexes

**Environment Variable Debugging**:
```bash
# Check if environment variables are loaded correctly
echo "DB_HOST: $DB_HOST"
echo "DB_PORT: $DB_PORT"
echo "DB_USER: $DB_USER"
echo "DB_NAME: $DB_NAME"
```

**Note**: The Python code automatically handles string-to-integer conversion for the port parameter, so both `DB_PORT=5432` and `DB_PORT="5432"` work correctly.

### Performance Tips

- Check for generated files in `graph_creation/result/` directory
- Monitor console output for processing status
- Clear cache if needed: `rm -rf shiny_app/.cache/`

### Data Validation

The system includes comprehensive validation:
- **YAML configuration**: Real-time validation with error messages
- **DAG file format**: Automatic dagitty syntax checking
- **Database queries**: Parameter validation and SQL injection prevention
- **File integrity**: Checksum validation for optimized files

## Examples

### Complete Workflow Example

#### 1. Setup Environment
```bash
# Clone and setup
git clone <repository-url>
cd CausalKnowledgeTrace

# Configure database credentials
cp doc/smaple.env .env
nano .env  # Edit with your database credentials

# Setup environment
./setup.sh
conda activate causalknowledgetrace
```

#### 2. Configure Analysis
```yaml
# user_input.yaml
exposure_cuis:
  - C0020538  # Hypertension
  - C4013784  # Hypertensive disease
outcome_cuis:
  - C2677888  # Alzheimer's disease
  - C0750901  # Dementia
min_pmids: 10
pub_year_cutoff: 2010
k_hops: 2
predication_type: "CAUSES"
```

#### 3. Launch Shiny Application
```bash
# Launch Shiny app
Rscript run_app.R
```

#### 4. (Optional) Test Graph Generation Manually
This step is optional - you can generate graphs through the web app instead:
```bash
cd graph_creation
python pushkin.py --yaml-config ../user_input.yaml \
  --host localhost --port 5432 --dbname causalehr \
  --user username --password password --schema causalehr \
  --markov-blanket --verbose
```

**Recommended workflow**: Use the Shiny app's "Graph Configuration" tab to generate graphs interactively rather than running the command line manually.

### DAG File Examples

#### Simple Three-Node DAG
```r
g <- dagitty('dag {
    Hypertension [exposure]
    Age
    Stroke [outcome]

    Age -> Hypertension
    Hypertension -> Stroke
    Age -> Stroke
}')
```

#### Complex Medical DAG
```r
g <- dagitty('dag {
    Hypertension [exposure]
    Diabetes
    Alzheimers_Disease [outcome]
    Age
    BMI
    Education

    Age -> Hypertension
    Age -> Diabetes
    Age -> Alzheimers_Disease
    BMI -> Hypertension
    BMI -> Diabetes
    Education -> Alzheimers_Disease
    Hypertension -> Alzheimers_Disease
    Diabetes -> Alzheimers_Disease
}')
```

## Support and Contributing

### Getting Help
1. **Check documentation**: Review this README and inline help
2. **Console output**: Monitor R console and terminal for detailed error messages
3. **Validation feedback**: Use real-time validation in the Shiny app
4. **Performance monitoring**: Check processing status and timing metrics

### System Requirements
- **Minimum**: 8GB RAM, 2GB disk space
- **Recommended**: 16GB RAM, 5GB disk space, SSD storage
- **Database**: PostgreSQL with SemMedDB (several GB)

## License

This project is provided for educational and research purposes. Please cite appropriately if used in academic work.
